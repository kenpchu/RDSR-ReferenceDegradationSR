From 5e3384bc042130ea04cd21f29ecd0ff24621eb7b Mon Sep 17 00:00:00 2001
From: whtang906 <whtang906@gmail.com>
Date: Wed, 1 May 2024 14:41:12 +0800
Subject: [PATCH 1/1] DualSRx4_run_patch

---
 main.py       |  17 +++++++--
 main_div2k.py |  41 ++++++++++++++++++++
 networks.py   | 102 +++++++++++++++++++++++++++++++++++++++++++++++++-
 options.py    |  32 +++++++++++++++-
 run.sh        |  17 +++++++++
 util.py       |  40 +++++++++++++++++++-
 6 files changed, 241 insertions(+), 8 deletions(-)
 create mode 100644 main_div2k.py
 create mode 100644 run.sh

diff --git a/main.py b/main.py
index 447bb5c..b9e2dee 100644
--- a/main.py
+++ b/main.py
@@ -1,5 +1,5 @@
 import os
-import tqdm
+# import tqdm
 
 from options import options
 from data import create_dataset
@@ -13,7 +13,10 @@ def train_and_eval(conf):
     learner = Learner(model)
     
     print('*' * 60 + '\nTraining started ...')
-    for iteration, data in enumerate(tqdm.tqdm(dataloader)):
+    # for iteration, data in enumerate(tqdm.tqdm(dataloader)):
+    for iteration, data in enumerate(dataloader):
+        if iteration % 500 == 0 or iteration % (conf.num_iters//10) == 0:
+            print(iteration)
         model.train(data)
         learner.update(iteration, model)
         
@@ -22,8 +25,16 @@ def train_and_eval(conf):
 
 def main():
     opt = options()
+
+    image_path_list = os.listdir(opt.conf.input_dir)
+    image_path_list = sorted(image_path_list)
+    image_path_list = image_path_list[opt.conf.start_index:opt.conf.start_index + opt.conf.train_count]
+    print(image_path_list)
+
+    for img_name in image_path_list:
+        print(img_name)
     # Run DualSR on all images in the input directory
-    for img_name in os.listdir(opt.conf.input_dir):
+    # for img_name in os.listdir(opt.conf.input_dir):
         conf = opt.get_config(img_name)
         train_and_eval(conf)
     
diff --git a/main_div2k.py b/main_div2k.py
new file mode 100644
index 0000000..97f0837
--- /dev/null
+++ b/main_div2k.py
@@ -0,0 +1,41 @@
+import os
+# import tqdm
+
+from options import options
+from data import create_dataset
+from DualSR import DualSR
+from learner import Learner
+
+
+def train_and_eval(conf):
+    model = DualSR(conf)
+    dataloader = create_dataset(conf)    
+    learner = Learner(model)
+
+    print('*' * 60 + '\nTraining started ...')
+    for iteration, data in enumerate(dataloader):
+        if iteration % 500 == 0 or iteration % (conf.num_iters//10) == 0:
+            print(iteration)
+        model.train(data)
+        learner.update(iteration, model)
+        
+    model.eval()
+
+
+def main():
+    opt = options()
+    # Run DualSR on all images in the input directory
+    image_path_list = os.listdir(opt.conf.input_dir)
+    image_path_list = sorted(image_path_list)
+    image_path_list = image_path_list[opt.conf.start_index:opt.conf.start_index + opt.conf.train_count]
+    print(image_path_list)
+
+    for img_name in image_path_list:
+        print(img_name)
+        conf = opt.get_div2k_config(img_name)
+        train_and_eval(conf)
+    
+
+
+if __name__ == '__main__':
+    main()
diff --git a/networks.py b/networks.py
index 447287c..2934964 100644
--- a/networks.py
+++ b/networks.py
@@ -1,6 +1,6 @@
 import torch
 import torch.nn as nn
-from util import make_1ch, make_3ch
+from util import make_1ch, make_3ch, calc_curr_k, analytic_kernel_w, resize_tensor_w_kernel
 import torch.nn.functional as F
 
 class Generator_UP(nn.Module):
@@ -35,11 +35,48 @@ class Generator_UP(nn.Module):
         return x
         
     def forward(self, x):
+        x = self.bilinear_upsample(x)
         x = self.bilinear_upsample(x)
         out = x + self.model(x)  # add skip connections
         return out
 
+class Generator_UPx2(nn.Module):
+    def __init__(self, channels=3, layers=8, features=64, scale_factor=2):
+        super(Generator_UPx2, self).__init__()
+        self.scale_factor = scale_factor
+        
+        model = [nn.Conv2d(channels, features, kernel_size=3, stride=1, padding=1),
+                 nn.ReLU(True)]
+        
+        for i in range(1, layers - 1):
+            model += [nn.Conv2d(features, features, kernel_size=3, stride=1, padding=1),
+                      nn.ReLU(True)]
+        
+        model += [nn.Conv2d(features, channels, kernel_size=3, stride=1, padding=1)]  
+        
+        self.model = nn.Sequential(*model)
         
+        self.bilinear_kernel = torch.FloatTensor([[[[9/16, 3/16], [3/16, 1/16]]],
+                                                  [[[3/16, 9/16], [1/16, 3/16]]],
+                                                  [[[3/16, 1/16], [9/16, 3/16]]],
+                                                  [[[1/16, 3/16], [3/16, 9/16]]]]).cuda()
+    
+    def bilinear_upsample(self, x):
+        x = torch.cat([x[:,:,:1,:], x, x[:,:,-1:,:]], dim=2)
+        x = torch.cat([x[:,:,:,:1], x, x[:,:,:,-1:]], dim=3)        
+        x = make_1ch(x)
+        x = F.conv2d(x, self.bilinear_kernel)
+        x = F.pixel_shuffle(x, 2)
+        x = make_3ch(x)
+        x = x[..., 1:-1, 1:-1]
+        return x
+        
+    def forward(self, x):
+        x = self.bilinear_upsample(x)
+        out = x + self.model(x)  # add skip connections
+        return out
+
+
 class Generator_DN(nn.Module):
     def __init__(self, features=64):
         super(Generator_DN, self).__init__()
@@ -47,6 +84,67 @@ class Generator_DN(nn.Module):
         self.G_kernel_size = 13
         # First layer
         self.first_layer = nn.Conv2d(in_channels=1, out_channels=features, kernel_size=struct[0], stride=1, bias=False)
+        self.first_layer = nn.Conv2d(in_channels=1, out_channels=features, kernel_size=struct[0], stride=2, bias=False)
+
+        feature_block = []  # Stacking intermediate layer
+        for layer in range(1, len(struct) - 1):
+            if struct[layer] == 3: # Downsample on the first layer with kernel_size=1
+                feature_block += [nn.Conv2d(in_channels=features, out_channels=features, kernel_size=struct[layer], stride=2, bias=False)]
+            else:
+                feature_block += [nn.Conv2d(in_channels=features, out_channels=features, kernel_size=struct[layer], bias=False)]
+        self.feature_block = nn.Sequential(*feature_block)
+        self.final_layer = nn.Conv2d(in_channels=features, out_channels=1, kernel_size=struct[-1], bias=False)
+
+    def forward(self, x):
+        # Swap axis of RGB image for the network to get a "batch" of size = 3 rather the 3 channels
+        x = make_1ch(x)
+        x = self.first_layer(x)
+        x = self.feature_block(x)
+        out = self.final_layer(x)
+        return make_3ch(out)
+
+    
+
+class Generator_DNk(nn.Module):
+    def __init__(self, features=64):
+        super(Generator_DNk, self).__init__()
+        struct = [7, 5, 3, 1, 1, 1]
+        # self.G_kernel_size = 13
+        self.G_kernel_size = 13 * 3 - 2 - (13//2) * 2
+        # First layer
+        self.first_layer = nn.Conv2d(in_channels=1, out_channels=features, kernel_size=struct[0], stride=1, bias=False)
+        self.first_layer = nn.Conv2d(in_channels=1, out_channels=features, kernel_size=struct[0], stride=2, bias=False)
+
+        feature_block = []  # Stacking intermediate layer
+        for layer in range(1, len(struct) - 1):
+            if struct[layer] == 3: # Downsample on the first layer with kernel_size=1
+                feature_block += [nn.Conv2d(in_channels=features, out_channels=features, kernel_size=struct[layer], stride=2, bias=False)]
+            else:
+                feature_block += [nn.Conv2d(in_channels=features, out_channels=features, kernel_size=struct[layer], bias=False)]
+        self.feature_block = nn.Sequential(*feature_block)
+        self.final_layer = nn.Conv2d(in_channels=features, out_channels=1, kernel_size=struct[-1], bias=False)
+
+    def forward(self, x):
+        # Swap axis of RGB image for the network to get a "batch" of size = 3 rather the 3 channels
+        x = make_1ch(x)
+        x = self.first_layer(x)
+        x = self.feature_block(x)
+        out = self.final_layer(x)
+        return make_3ch(out)
+
+    def calc_ker(self):
+        curr_k = calc_curr_k(self.parameters())
+        curr_k_x4 = analytic_kernel_w(curr_k.cuda())
+        return curr_k_x4
+
+
+class Generator_DNx2(nn.Module):
+    def __init__(self, features=64):
+        super(Generator_DNx2, self).__init__()
+        struct = [7, 5, 3, 1, 1, 1]
+        self.G_kernel_size = 13
+        # First layer
+        self.first_layer = nn.Conv2d(in_channels=1, out_channels=features, kernel_size=struct[0], stride=1, bias=False)
 
         feature_block = []  # Stacking intermediate layer
         for layer in range(1, len(struct) - 1):
@@ -117,4 +215,4 @@ def weights_init_G_UP(m):
     if m.__class__.__name__.find('Conv') != -1:
         nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in', nonlinearity='relu')
         if hasattr(m.bias, 'data'):
-            m.bias.data.fill_(0)
\ No newline at end of file
+            m.bias.data.fill_(0)
diff --git a/options.py b/options.py
index 27b732e..9d35aa3 100644
--- a/options.py
+++ b/options.py
@@ -1,6 +1,7 @@
 import argparse
 import torch
 import os
+from datetime import datetime
 
 
 class options:
@@ -39,9 +40,16 @@ class options:
         self.parser.add_argument('--eval_iters', type=int, default=100, help='for debug purpose')
         self.parser.add_argument('--plot_iters', type=int, default=200, help='for debug purpose')
         self.parser.add_argument('--debug', action='store_true', help='plot intermediate results')
+
+        self.parser.add_argument('--start_index', type=int, default=0)
+        self.parser.add_argument('--train_count', type=int, default=200)
         
         self.conf = self.parser.parse_args()
-        
+
+        timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
+        print(timestamp)
+        self.conf.output_dir = self.conf.output_dir + '_' + timestamp
+
         if not os.path.exists(self.conf.output_dir):
             os.makedirs(self.conf.output_dir)
             
@@ -53,13 +61,33 @@ class options:
         self.conf.input_image_path = os.path.join(self.conf.input_dir, img_name)
         self.conf.kernel_path = os.path.join(self.conf.kernel_dir, self.conf.abs_img_name + '.mat') if self.conf.kernel_dir != '' else None
         self.conf.gt_path = os.path.join(self.conf.gt_dir, img_name) if self.conf.gt_dir != '' else None
-        
+
+        # Need to modify
+        im_no = os.path.basename(self.conf.input_image_path).split('.')[0].split('_')[1]
+        self.conf.kernel_path = os.path.join(self.conf.kernel_dir, f'kernel_{im_no}.mat') if self.conf.kernel_dir != '' else None
+        self.conf.gt_path = os.path.join(self.conf.gt_dir, f'img_{im_no}_gt.png') if self.conf.gt_dir != '' else None
+
         print('*' * 60 + '\nRunning DualSR ...')
         print('input image: \'%s\'' %self.conf.input_image_path)
         print('grand-truth image: \'%s\'' %self.conf.gt_path)
         print('grand-truth kernel: \'%s\'' %self.conf.kernel_path)
         return self.conf
     
+    def get_div2k_config(self, img_name):
+        self.conf.abs_img_name = os.path.splitext(img_name)[0]
+        self.conf.input_image_path = os.path.join(self.conf.input_dir, img_name)
+        self.conf.kernel_path = os.path.join(self.conf.kernel_dir, self.conf.abs_img_name + '.mat') if self.conf.kernel_dir != '' else None
+        self.conf.gt_path = os.path.join(self.conf.gt_dir, img_name) if self.conf.gt_dir != '' else None
 
+        # Need to modify
+        im_no = os.path.basename(self.conf.input_image_path)[:4]
+        self.conf.kernel_path = os.path.join(self.conf.kernel_dir, f'kernel_{im_no}.mat') if self.conf.kernel_dir != '' else None
+        self.conf.gt_path = os.path.join(self.conf.gt_dir, f'{im_no}.png') if self.conf.gt_dir != '' else None
+
+        print('*' * 60 + '\nRunning DualSR ...')
+        print('input image: \'%s\'' %self.conf.input_image_path)
+        print('grand-truth image: \'%s\'' %self.conf.gt_path)
+        print('grand-truth kernel: \'%s\'' %self.conf.kernel_path)
+        return self.conf
 
 
diff --git a/run.sh b/run.sh
new file mode 100644
index 0000000..d97882f
--- /dev/null
+++ b/run.sh
@@ -0,0 +1,17 @@
+TIMESTAMP=`date "+%Y-%m-%d_%H-%M-%S"`
+echo $TIMESTAMP
+mkdir -p log
+
+# Run DIV2K dataset
+# CUDA_VISIBLE_DEVICES=1 python main_div2k.py --input_dir ../datasets/DIV2K/DIV2K_train_LR_unknown/X4 \
+#                                             --gt_dir ../datasets/DIV2K/DIV2K_train_HR \
+#                                             --scale_factor 4 --scale_factor_downsampler 0.25 \
+#                                             --start_index 0 --train_count 800 \
+#                                             --output_dir results >> ./log/DualSR_$TIMESTAMP.log 2>&1 &
+
+# Run DIV2KRK dataset
+# CUDA_VISIBLE_DEVICES=1 python main.py --input_dir ../datasets/DIV2KRK/lr_x4 \
+#                                       --gt_dir ../datasets/DIV2KRK/gt \
+#                                       --scale_factor 4 --scale_factor_downsampler 0.25 \
+#                                       --start_index 0 --train_count 100 \
+#                                       --output_dir results >> ./log/DualSR_$TIMESTAMP.log 2>&1 &
diff --git a/util.py b/util.py
index cada2e3..bff4354 100644
--- a/util.py
+++ b/util.py
@@ -226,4 +226,42 @@ def cal_y_psnr(A, B, border):
     mse=np.mean(e**2);
     psnr_cur=10*np.log10(255*255/mse);
     
-    return psnr_cur
\ No newline at end of file
+    return psnr_cur
+
+def analytic_kernel_w(k):
+    """Calculate the X4 kernel from the X2 kernel (for proof see appendix in paper)"""
+    k_size = k.shape[0]
+    # Calculate the big kernels size
+    big_k = torch.zeros((3 * k_size - 2, 3 * k_size - 2)).cuda()
+    # Loop over the small kernel to fill the big one
+    for r in range(k_size):
+        for c in range(k_size):
+            big_k[2 * r:2 * r + k_size, 2 * c:2 * c + k_size] += k[r, c] * k
+    # Crop the edges of the big kernel to ignore very small values and increase run time of SR
+    crop = k_size // 2
+    cropped_big_k = big_k[crop:-crop, crop:-crop]
+    # Normalize to 1
+    return cropped_big_k / cropped_big_k.sum()
+
+
+def post_process_k(k, n):
+    """Move the kernel to the CPU, eliminate negligible values, and centralize k"""
+    k = move2cpu(k)
+    # Zeroize negligible values
+    significant_k = zeroize_negligible_val(k, n)
+    # Force centralization on the kernel
+    centralized_k = kernel_shift(significant_k, sf=2)
+    # return shave_a2b(centralized_k, k)
+    return centralized_k
+
+
+def zeroize_negligible_val(k, n):
+    """Zeroize values that are negligible w.r.t to values in k"""
+    # Sort K's values in order to find the n-th largest
+    k_sorted = np.sort(k.flatten())
+    # Define the minimum value as the 0.75 * the n-th largest value
+    k_n_min = 0.75 * k_sorted[-n - 1]
+    # Clip values lower than the minimum value
+    filtered_k = np.clip(k - k_n_min, a_min=0, a_max=100)
+    # Normalize to sum to 1
+    return filtered_k / filtered_k.sum()
-- 
2.17.1

